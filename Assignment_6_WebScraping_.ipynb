{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadzav23-ux/Mohammad_DTSC3020_Fall2025/blob/main/Assignment_6_WebScraping_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) ‚Äî Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **‚ÄúWrite your answer here‚Äù** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‚Äë15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‚Äë15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‚Äë15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I7DLq9nEu-tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce5e0b8-3e6e-4edb-eb9d-2ea33b1bba86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        " #Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ov8pXh65u-tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e8de48-ffb9-40de-fa50-c06c8f11fe63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common helpers loaded.\n"
          ]
        }
      ],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 ‚Äî IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (‚â•4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` ‚Üí **UPPERCASE**; `Numeric` ‚Üí **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ‚â•3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q1_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d03b00-73a4-4fa8-c9b1-e4f4d0d9630a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data_q1.csv saved successfully.\n",
            "\n",
            "üîù Top 15 Countries by Numeric code:\n",
            "\n",
            "                                               Country Alpha-2 code  \\\n",
            "247                                             Zambia           ZM   \n",
            "246                                              Yemen           YE   \n",
            "192                                              Samoa           WS   \n",
            "244                                  Wallis and Futuna           WF   \n",
            "240                 Venezuela (Bolivarian Republic of)           VE   \n",
            "238                                         Uzbekistan           UZ   \n",
            "237                                            Uruguay           UY   \n",
            "35                                        Burkina Faso           BF   \n",
            "243                              Virgin Islands (U.S.)           VI   \n",
            "236                     United States of America (the)           US   \n",
            "219                       Tanzania, United Republic of           TZ   \n",
            "108                                        Isle of Man           IM   \n",
            "113                                             Jersey           JE   \n",
            "92                                            Guernsey           GG   \n",
            "234  United Kingdom of Great Britain and Northern I...           GB   \n",
            "\n",
            "    Alpha-3 code  Numeric  \n",
            "247          ZMB      894  \n",
            "246          YEM      887  \n",
            "192          WSM      882  \n",
            "244          WLF      876  \n",
            "240          VEN      862  \n",
            "238          UZB      860  \n",
            "237          URY      858  \n",
            "35           BFA      854  \n",
            "243          VIR      850  \n",
            "236          USA      840  \n",
            "219          TZA      834  \n",
            "108          IMN      833  \n",
            "113          JEY      832  \n",
            "92           GGY      831  \n",
            "234          GBR      826  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2683353077.py:10: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  tables = pd.read_html(html)\n",
            "/tmp/ipython-input-2683353077.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ],
      "source": [
        "# Q1 ‚Äî Write your answer here\n",
        "\n",
        "# Step 1: Fetch HTML\n",
        "url = \"https://www.iban.com/country-codes\"\n",
        "html = fetch_html(url)\n",
        "\n",
        "# Step 2: Extract table\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\"\"\"\n",
        "    tables = pd.read_html(html)\n",
        "    # Pick the first table with at least 3 columns\n",
        "    for t in tables:\n",
        "        if t.shape[1] >= 3:\n",
        "            df = t.copy()\n",
        "            break\n",
        "    df = flatten_headers(df)\n",
        "    return df\n",
        "\n",
        "# Step 3: Clean table\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\"\"\"\n",
        "    # Rename columns for consistency\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Ensure standard column names\n",
        "    expected_cols = [\"Country\", \"Alpha-2 code\", \"Alpha-3 code\", \"Numeric\"]\n",
        "    df = df[[c for c in df.columns if c in expected_cols]]\n",
        "\n",
        "    # Trim spaces\n",
        "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "    # Convert Alpha codes to uppercase\n",
        "    for col in [\"Alpha-2 code\", \"Alpha-3 code\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].str.upper()\n",
        "\n",
        "    # Convert Numeric to integer (nullable)\n",
        "    if \"Numeric\" in df.columns:\n",
        "        df[\"Numeric\"] = pd.to_numeric(df[\"Numeric\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # Drop rows missing Country or Numeric\n",
        "    df = df.dropna(subset=[\"Country\", \"Numeric\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Step 4: Sort and get Top 15\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\"\"\"\n",
        "    df_sorted = df.sort_values(by=\"Numeric\", ascending=False)\n",
        "    return df_sorted.head(top)\n",
        "\n",
        "# Run all steps\n",
        "df_raw = q1_read_table(html)\n",
        "df_clean = q1_clean(df_raw)\n",
        "df_top15 = q1_sort_top(df_clean)\n",
        "\n",
        "# Step 5: Output results\n",
        "df_clean.to_csv(\"data_q1.csv\", index=False)\n",
        "print(\"‚úÖ data_q1.csv saved successfully.\\n\")\n",
        "print(\"üîù Top 15 Countries by Numeric code:\\n\")\n",
        "print(df_top15)\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 ‚Äî Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` ‚Üí **int** (non-digits ‚Üí 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q2 Skeleton (fill the TODOs) ---\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    TODO: implement with BeautifulSoup on '.athing' and its sibling '.subtext'.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_parse_items\")\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\n",
        "    TODO: cast points/comments/rank to int (non-digits -> 0). Fill text fields.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_clean\")\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N. TODO: implement.\"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q2_sort_top\")\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q2_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567dfce7-d55f-4914-eb99-2820169280f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data_q2.csv saved successfully.\n",
            "\n",
            "üîù Top 15 Hacker News Stories by Points:\n",
            "\n",
            "    rank                                              title  points  comments  \\\n",
            "12    13  YouTube Removes Windows 11 Bypass Tutorials, C...     490       183   \n",
            "7      8                            Why I love OCaml (2023)     311       210   \n",
            "25    26  VLC's Jean-Baptiste Kempf Receives the Europea...     277        47   \n",
            "27    28                              James Watson has died     271       150   \n",
            "4      5  Myna: Monospace typeface designed for symbol-h...     230        85   \n",
            "0      1                                Why is Zig so cool?     229       109   \n",
            "8      9                             Ruby Solved My Problem     198        77   \n",
            "5      6                                How did I get here?     175        33   \n",
            "3      4                       Becoming a Compiler Engineer     163        66   \n",
            "1      2  Snapchat open-sources Valdi a cross-platform U...     154        37   \n",
            "21    22                     Angel Investors, a Field Guide     122        27   \n",
            "26    27  FAA to restrict commercial rocket launches to ...     121        59   \n",
            "16    17                            Venn Diagram for 7 Sets     105        23   \n",
            "17    18  Transducer: Composition, abstraction, performa...      84         1   \n",
            "2      3       Mullvad: Shutting down our search proxy Leta      80        34   \n",
            "\n",
            "            user  \n",
            "12   WaitWaitWha  \n",
            "7          art-w  \n",
            "25     kirschner  \n",
            "27     granzymes  \n",
            "4    birdculture  \n",
            "0      vitalnodo  \n",
            "8   joemasilotti  \n",
            "5      zachlatta  \n",
            "3      lalitkale  \n",
            "1    yehiaabdelm  \n",
            "21      azhenley  \n",
            "26       bookmtn  \n",
            "16   bramadityaw  \n",
            "17      defmarco  \n",
            "2      holysoles  \n"
          ]
        }
      ],
      "source": [
        "# Q2 ‚Äî Write your answer here\n",
        "\n",
        "# Step 1: Fetch HTML\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "html = fetch_html(url)\n",
        "\n",
        "# Step 2: Parse front-page stories\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    stories = soup.select(\".athing\")\n",
        "    data = []\n",
        "\n",
        "    for story in stories:\n",
        "        rank_tag = story.select_one(\".rank\")\n",
        "        title_tag = story.select_one(\".titleline a\")\n",
        "        subtext = story.find_next_sibling(\"tr\").select_one(\".subtext\")\n",
        "\n",
        "        rank = rank_tag.get_text(strip=True).replace(\".\", \"\") if rank_tag else \"0\"\n",
        "        title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "        link = title_tag[\"href\"] if title_tag and title_tag.has_attr(\"href\") else \"\"\n",
        "\n",
        "        # subtext may be missing (e.g., job posts)\n",
        "        if subtext:\n",
        "            points_tag = subtext.select_one(\".score\")\n",
        "            user_tag = subtext.select_one(\".hnuser\")\n",
        "            comments_tag = subtext.find_all(\"a\")[-1]\n",
        "        else:\n",
        "            points_tag = user_tag = comments_tag = None\n",
        "\n",
        "        points = points_tag.get_text(strip=True) if points_tag else \"0\"\n",
        "        user = user_tag.get_text(strip=True) if user_tag else \"\"\n",
        "        comments_text = comments_tag.get_text(strip=True) if comments_tag else \"0\"\n",
        "\n",
        "        # Sometimes comments say \"discuss\" or \"hide\"\n",
        "        if not comments_text or \"comment\" not in comments_text:\n",
        "            comments_text = \"0\"\n",
        "\n",
        "        data.append({\n",
        "            \"rank\": rank,\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"user\": user,\n",
        "            \"points\": points,\n",
        "            \"comments\": comments_text\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Step 3: Clean numeric fields and fill missing\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\"\"\"\n",
        "    def extract_int(text):\n",
        "        text = str(text)\n",
        "        digits = re.findall(r\"\\d+\", text)\n",
        "        return int(digits[0]) if digits else 0\n",
        "\n",
        "    for col in [\"rank\", \"points\", \"comments\"]:\n",
        "        df[col] = df[col].apply(extract_int)\n",
        "\n",
        "    df = df.fillna(\"\")\n",
        "    return df\n",
        "\n",
        "# Step 4: Sort by points\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N.\"\"\"\n",
        "    df_sorted = df.sort_values(by=\"points\", ascending=False)\n",
        "    return df_sorted.head(top)\n",
        "\n",
        "# Step 5: Run pipeline\n",
        "df_raw = q2_parse_items(html)\n",
        "df_clean = q2_clean(df_raw)\n",
        "df_top15 = q2_sort_top(df_clean)\n",
        "\n",
        "# Step 6: Save and preview\n",
        "df_clean.to_csv(\"data_q2.csv\", index=False)\n",
        "print(\"‚úÖ data_q2.csv saved successfully.\\n\")\n",
        "print(\"üîù Top 15 Hacker News Stories by Points:\\n\")\n",
        "print(df_top15[[\"rank\", \"title\", \"points\", \"comments\", \"user\"]])\n",
        "\n",
        "\n"
      ],
      "id": "q2_skeleton_answer"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}